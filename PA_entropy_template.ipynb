{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "\n",
    "from gerrychain import Graph, GeographicPartition, Partition, Election, accept\n",
    "from gerrychain.updaters import Tally, cut_edges\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from gerrychain.random import random\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from gerrychain import MarkovChain\n",
    "from gerrychain.constraints import single_flip_contiguous\n",
    "from gerrychain.proposals import recom, propose_random_flip\n",
    "from gerrychain.accept import always_accept\n",
    "from gerrychain.metrics import polsby_popper\n",
    "from gerrychain import constraints\n",
    "from gerrychain.constraints import no_vanishing_districts\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pandas\n",
    "\n",
    "import math\n",
    "\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "#from IPython.display import clear_output\n",
    "\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup -- SLOW\n",
    "\n",
    "shapefile = \"https://github.com/mggg-states/PA-shapefiles/raw/master/PA/PA_VTD.zip\"\n",
    "\n",
    "df = gpd.read_file(shapefile)\n",
    "\n",
    "county_col = \"COUNTYFP10\"\n",
    "pop_col = \"TOT_POP\"\n",
    "uid = \"GEOID10\"\n",
    "\n",
    "\n",
    "graph = Graph.from_geodataframe(df,ignore_errors=True)\n",
    "graph.add_data(df,list(df))\n",
    "graph = nx.relabel_nodes(graph, df[uid])\n",
    "counties = (set(list(df[county_col])))\n",
    "countydict = dict(graph.nodes(data=county_col))\n",
    "\n",
    "\n",
    "#print(counties)\n",
    "#print(countydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totpop = 0\n",
    "num_districts = 18\n",
    "for n in graph.nodes():\n",
    "    graph.node[n][\"TOT_POP\"] = int(graph.node[n][\"TOT_POP\"])\n",
    "    totpop += graph.node[n][\"TOT_POP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updaters1={\n",
    "        \"polsby_popper\" : polsby_popper,\n",
    "        \"cut_edges\": cut_edges,\n",
    "        \"population\": Tally(pop_col, alias=\"population\"),\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in graph.nodes():\n",
    "    graph.nodes[n]['538CPCT__1'] = int(graph.nodes[n]['538CPCT__1'])\n",
    "    graph.nodes[n]['538DEM_PL'] = int(graph.nodes[n]['538DEM_PL'])\n",
    "    graph.nodes[n]['538GOP_PL'] = int(graph.nodes[n]['538GOP_PL'])\n",
    "    graph.nodes[n]['8THGRADE_1'] = int(graph.nodes[n]['8THGRADE_1'])\n",
    "    \n",
    "partition_2011 = Partition(graph, \"2011_PLA_1\", updaters1)\n",
    "partition_GOV = Partition(graph, \"GOV\", updaters1)\n",
    "partition_TS = Partition(graph, \"TS\", updaters1)\n",
    "partition_REMEDIAL = Partition(graph, \"REMEDIAL_P\", updaters1)\n",
    "partition_CPCT = Partition(graph, \"538CPCT__1\", updaters1)\n",
    "partition_DEM = Partition(graph, \"538DEM_PL\", updaters1)\n",
    "partition_GOP = Partition(graph, \"538GOP_PL\", updaters1)\n",
    "partition_8th = Partition(graph, \"8THGRADE_1\", updaters1)\n",
    "\n",
    "partitions = [partition_2011, partition_GOV, partition_TS,\n",
    "                  partition_REMEDIAL, partition_CPCT, partition_DEM,\n",
    "                  partition_GOP, partition_8th]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.nodes())\n",
    "starting_partition = GeographicPartition(\n",
    "    graph,\n",
    "    assignment=\"GOV\",\n",
    "    updaters1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_splits_dict(partition):\n",
    "    ''' returns a dictionary with keys as district numbers and values Counter() dictionaries\n",
    "        these counter dictionaries have pairs COUNTY_ID : NUM which counts the number of VTDS\n",
    "        in the county in the district\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    county_splits = {k:[] for k in counties}\n",
    "    county_splits = {  k:[countydict[v] for v in d] for k,d in partition.assignment.parts.items()   }\n",
    "    county_splits = {k: Counter(v) for k,v in county_splits.items()}\n",
    "    return county_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def district_splits_dict(county_splits):\n",
    "    district_splits = {k:[] for k in counties}\n",
    "    \n",
    "    for county in counties:\n",
    "        districts = {}\n",
    "        for district in county_splits.keys():\n",
    "            if county in county_splits[district].keys():\n",
    "                district_splits[county].append(district)\n",
    "    return district_splits            \n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# returns a dictionary that maps a county to a list of VTDs that are in the counth\n",
    "\n",
    "def reverse_countydict():\n",
    "    rev = {k:[] for k in counties}\n",
    "    for county in counties:\n",
    "        for vtd in countydict.keys():\n",
    "            if countydict[vtd] == county:\n",
    "                rev[county].append(vtd)\n",
    "    return rev\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# various functions to measure splits according to the proposed PA rule. Feel free to ignore\n",
    "\n",
    "def pieces_allowed():\n",
    "    district_splits ={}\n",
    "    \n",
    "    for county in counties:\n",
    "        sg=graph.subgraph(n for n, v in graph.nodes(data=True) if v[county_col]==county)\n",
    "        pop = 0;\n",
    "        \n",
    "        for n in sg.nodes():\n",
    "            pop += sg.node[n][\"TOT_POP\"]\n",
    "        \n",
    "        district_splits[county] = math.ceil(pop/(totpop/num_districts)) + 1\n",
    "    return district_splits\n",
    "\n",
    "def other_pieces_allowed():\n",
    "    district_splits ={}\n",
    "    \n",
    "    for county in counties:\n",
    "        sg=graph.subgraph(n for n, v in graph.nodes(data=True) if v[county_col]==county)\n",
    "        pop = 0;\n",
    "        \n",
    "        for n in sg.nodes():\n",
    "            pop += sg.node[n][\"TOT_POP\"]\n",
    "        \n",
    "        district_splits[county] = math.ceil(pop/(totpop/num_districts))\n",
    "    return district_splits\n",
    "\n",
    "def too_many_pieces(partition):\n",
    "    district_splits = district_splits_dict(county_splits_dict(partition))\n",
    "    pieces = pieces_allowed()\n",
    "    too_many = 0\n",
    "    \n",
    "    for county in counties:\n",
    "        if len(district_splits[county]) > pieces[county]:\n",
    "            too_many += 1\n",
    "    \n",
    "    return too_many\n",
    "\n",
    "def other_too_many_pieces(partition):\n",
    "    district_splits = district_splits_dict(county_splits_dict(partition))\n",
    "    pieces = other_pieces_allowed()\n",
    "    too_many = 0\n",
    "    \n",
    "    for county in counties:\n",
    "        if len(district_splits[county]) > pieces[county]:\n",
    "            too_many += 1\n",
    "    \n",
    "    return too_many\n",
    "\n",
    "def how_many_more(partition):\n",
    "    district_splits = district_splits_dict(county_splits_dict(partition))\n",
    "    pieces = pieces_allowed()\n",
    "    too_many = 0\n",
    "    \n",
    "    for county in counties:\n",
    "        if len(district_splits[county]) > pieces[county]:\n",
    "            too_many += len(district_splits[county]) - pieces[county]\n",
    "    return too_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_in_county(part,sg):\n",
    "    num_ce_in_count = 0\n",
    "    for edge in part[\"cut_edges\"]:\n",
    "         if edge in sg.edges():\n",
    "            num_ce_in_count += 1\n",
    "    return num_ce_in_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_split_score_1(part):\n",
    "    sum = 0\n",
    "    \n",
    "    for county in counties:\n",
    "        sg=graph.subgraph(n for n, v in graph.nodes(data=True) if v[county_col]==county)\n",
    "        sum += cut_in_county(part,sg) / len(sg.edges())\n",
    "      \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_split_score_2(part):\n",
    "    ce_btn_counties = 0\n",
    "    \n",
    "    for ce in part[\"cut_edges\"]:\n",
    "        if int(countydict[str(ce[0])]) != int(countydict[str(ce[1])]):\n",
    "            ce_btn_counties += 1\n",
    "    \n",
    "    return ce_btn_counties / len(part[\"cut_edges\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def vtds_per_county(county_splits):\n",
    "#    vtds = {}\n",
    "#    \n",
    "#    for counter in county_splits.values():\n",
    "#        for county in counter.keys():\n",
    "#            if county in vtds:\n",
    "#                vtds[county] += counter[county]\n",
    "#            else:\n",
    "#                vtds[county] = counter[county]\n",
    "#    return vtds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pops_per_county(county_splits,rev):\n",
    "    pops = {}\n",
    "    \n",
    "    for county in rev.keys():\n",
    "        pop = 0\n",
    "        for vtd in rev[county]:\n",
    "            pop += graph.nodes[vtd][\"TOT_POP\"]\n",
    "        pops[county] = pop\n",
    "    return pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def vtds_per_district(county_splits):\n",
    "#    vtds = {}\n",
    "#    \n",
    "#    for district in county_splits.keys():\n",
    "#        sum = 0\n",
    "#        counter = county_splits[district]\n",
    "#        for vtd in counter.values():\n",
    "#            sum += vtd\n",
    "#        vtds[district] = sum\n",
    "#    return vtds        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pops_per_district(partition):\n",
    "    dictionary = dict(partition.assignment)\n",
    "    pops = {}\n",
    "    \n",
    "    for i in range(num_districts):\n",
    "        for vtd in dictionary.keys():\n",
    "            if i+1 in pops and dictionary[vtd] == i + 1:\n",
    "                pops[i+1] += graph.nodes[vtd][\"TOT_POP\"]\n",
    "            elif dictionary[vtd] == i+1:\n",
    "                pops[i+1] = graph.nodes[vtd][\"TOT_POP\"]\n",
    "    return pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def total_vtds(vtds):\n",
    "#    total = 0\n",
    "#    \n",
    "#    for county in vtds.keys():\n",
    "#        total += vtds[county]\n",
    "#    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def total_pops(pops):\n",
    "#    total = 0\n",
    "#    for pop in pops.values():\n",
    "#        total += pop\n",
    "#    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VTDs_to_Counties(partition):\n",
    "    '''\n",
    "    Consumes a partition which is converted into a dictionary with keys as districts\n",
    "    and values as a list of VTDs that are in that district.\n",
    "    Returns a dictionary with keys as districts and values\n",
    "    as dictionaries of county-population key-value pairs. This represents the population\n",
    "    of each county that is in each district.\n",
    "    '''\n",
    "    district_dict = dict(partition.parts)\n",
    "    new_district_dict = dict(partition.parts)\n",
    "    for district in district_dict.keys():\n",
    "        vtds = district_dict[district]\n",
    "        county_pop = {k:0 for k in counties}\n",
    "        for vtd in vtds:\n",
    "            county_pop[countydict[vtd]] += graph.nodes[vtd][pop_col]\n",
    "        new_district_dict[district] = county_pop\n",
    "    return new_district_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_to_score(dictionary):\n",
    "    district_dict = dictionary\n",
    "    score = 0\n",
    "    for dist in district_dict.keys():\n",
    "        counties_and_pops = district_dict[dist]\n",
    "        total = sum(counties_and_pops.values())\n",
    "        fractional_sum = 0\n",
    "        for county in counties_and_pops.keys():\n",
    "            fractional_sum += np.sqrt(counties_and_pops[county]/total)\n",
    "        score += total*fractional_sum\n",
    "    return score\n",
    "\n",
    "def invert_dict(dictionary):\n",
    "    new_dict = defaultdict(dict)\n",
    "    for k,v in dictionary.items():\n",
    "        for k2,v2 in v.items():\n",
    "            new_dict[k2][k] = v2\n",
    "    return new_dict\n",
    "    \n",
    "def moon_score(partition):\n",
    "    dictionary = VTDs_to_Counties(partition)\n",
    "    return dictionary_to_score(dictionary) + dictionary_to_score(invert_dict(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def p_i_given_j(county_splits, vtds, district_i, county_j):\n",
    "#    counter = county_splits[district_i]\n",
    "#    intersection = counter[str(county_j)]\n",
    "#    \n",
    "#    return intersection / vtds[str(county_j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_edge_count = {}\n",
    "for i in counties:\n",
    "    county_graph = graph.subgraph([n for n,v in graph.nodes(data = True) if v[county_col] == i])\n",
    "    total_edges = len(county_graph.edges())\n",
    "    county_edge_count[i] = total_edges\n",
    "countynodelist = {\n",
    "    county: frozenset(\n",
    "        [node for node in graph.nodes() if graph.nodes[node][county_col] == county]) for county in counties\n",
    "}\n",
    "\n",
    "\n",
    "county_subgraphs = {county: graph.subgraph([n for n in graph.nodes if graph.nodes[n][county_col] == county]) for county in counties}\n",
    "county_edges = {county: len(county_subgraphs[county].edges()) for county in counties}\n",
    "total_edges = sum(county_edges.values())\n",
    "\n",
    "def cut_edges_in_county(partition):\n",
    "   '''returns an integer score that is the sum over all the county scores. The scores are computed by taking\n",
    "      number of cut egdes and dividing by the number of total edges.\n",
    "   '''\n",
    "   county_cut_edge_dict = {}\n",
    "   cut_edge_set = partition[\"cut_edges\"]\n",
    "   for k in cut_edge_set:\n",
    "       vtd_1 = k[0]\n",
    "       vtd_2 = k[1]\n",
    "       county_1 = countydict.get(vtd_1)\n",
    "       county_2 = countydict.get(vtd_2)\n",
    "       if county_1 == county_2:\n",
    "           if county_1 in county_cut_edge_dict.keys():\n",
    "               county_cut_edge_dict[county_1] += 1\n",
    "           else:\n",
    "               county_cut_edge_dict[county_1] = 1\n",
    "   ratio_dict = {}\n",
    "   for i in county_cut_edge_dict.keys():\n",
    "       ratio = county_cut_edge_dict[i]/county_edge_count[i]\n",
    "       ratio_dict[i] = ratio\n",
    "   return sum(ratio_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_edges_in_district(partition):\n",
    "    cut_edges_between = 0\n",
    "    cut_edge_set = partition[\"cut_edges\"]\n",
    "    for i in cut_edge_set:\n",
    "        vtd_1 = i[0]\n",
    "        vtd_2 = i[1]\n",
    "        county_1 = countydict.get(vtd_1)\n",
    "        county_2 = countydict.get(vtd_2)\n",
    "        if county_1 != county_2:\n",
    "            cut_edges_between += 1\n",
    "    num_cut_edges = len(cut_edge_set)\n",
    "    score = cut_edges_between/num_cut_edges\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def q_j(vtds_d,county_j,total):\n",
    "#    return vtds[county_j] / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def power_entropy(county_splits,vtds,total,alpha):\n",
    "#    entropy = 0\n",
    "#    for county_j in counties:\n",
    "#        inner_sum = 0\n",
    "#        q = q_j(vtds,county_j,total)\n",
    "#        for district_i in range(num_districts):\n",
    "#            p = p_i_given_j(county_splits, vtds,district_i+1,county_j)\n",
    "#            inner_sum += p ** (1-alpha)\n",
    "#        entropy += 1/q * (inner_sum-1)\n",
    "#        #print(1/q * (inner_sum-1))\n",
    "#    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def Shannon_entropy(county_splits, vtds, total):\n",
    "#    entropy = 0\n",
    "#    for county_j in counties:\n",
    "#        inner_sum = 0\n",
    "#        q = q_j(vtds,county_j,total)\n",
    "#        for district_i in range(num_districts):\n",
    "#            p = p_i_given_j(county_splits, vtds,district_i+1,county_j)\n",
    "#            if p != 0:\n",
    "#                inner_sum += p * math.log(1/p)\n",
    "#        entropy += q * (inner_sum)\n",
    "#        #print(1/q * (inner_sum-1))\n",
    "#    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def p_i(vtds,district_i,total):\n",
    "#    return vtds[district_i] / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def q_j_given_i(county_splits, vtds_d, district_i, county_j):\n",
    "#    counter = county_splits[district_i]\n",
    "#    intersection = counter[str(county_j)]\n",
    "#    \n",
    "#    return intersection / vtds_d[district_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def other_power_entropy(county_splits,vtds_d,total,alpha):\n",
    "#    entropy = 0\n",
    "#    for district_i in range(num_districts):\n",
    "#        innersum = 0\n",
    "#        p = p_i(vtds_d,district_i+1,total)\n",
    "#        for county_j in counties:\n",
    "#            q = q_j_given_i(county_splits,vtds_d,district_i+1,county_j)\n",
    "#            innersum += q ** (1-alpha)\n",
    "#        entropy += 1/p * (innersum-1)\n",
    "#    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def symmetric_power_entropy(county_splits,vtds_c,vtds_d,total,alpha):\n",
    "#    return power_entropy(county_splits,vtds_c,total,alpha) + other_power_entropy(county_splits,vtds_d,total,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_entropy(partition):\n",
    "    entropy = 0\n",
    "    total_edges = len(graph.edges())\n",
    "    countynodelist = {\n",
    "        county: frozenset(\n",
    "            [node for node in graph.nodes() if graph.nodes[node][county_col] == county]) for county in counties\n",
    "    }\n",
    "    districts_in_counties = {\n",
    "        county: frozenset([partition.assignment[d] for d in countynodelist[county]]) for county in counties\n",
    "    }\n",
    "    for county in counties:\n",
    "        county_subgraph = graph.subgraph([n for n in graph.nodes if graph.nodes[n][county_col] == county])\n",
    "        county_edges = len(county_subgraph.edges())\n",
    "        for (district1, district2) in combinations_with_replacement(districts_in_counties[county],2):\n",
    "            p_ij = len([e for e in county_subgraph.edges() if set(\n",
    "                [partition.assignment[e[0]], partition.assignment[e[1]]]) == set([district1, district2])])\n",
    "            p_ij = p_ij/len(county_subgraph.edges())\n",
    "            if (p_ij != 0):\n",
    "                entropy -= p_ij*np.log(p_ij)*county_edges/total_edges\n",
    "    return entropy\n",
    "\n",
    "def num_of_splittings(partition):\n",
    "    dictionary = county_splits_dict(partition)\n",
    "    counter = 0\n",
    "    for district in dictionary.keys():\n",
    "        counter += len(dictionary[district])\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################3\n",
    "\n",
    "# returns a dictionary that maps a county to a list of VTDs that are in the counth\n",
    "\n",
    "def reverse_countydict():\n",
    "    rev = {k:[] for k in counties}\n",
    "    for county in counties:\n",
    "        for vtd in countydict.keys():\n",
    "            if countydict[vtd] == county:\n",
    "                rev[county].append(vtd)\n",
    "    return rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################3\n",
    "\n",
    "# calculates the population of a given county\n",
    "\n",
    "def county_pop(rev, county_j):\n",
    "    pop = 0\n",
    "    for vtd in rev[county_j]:\n",
    "        pop += graph.nodes[vtd][\"TOT_POP\"]\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################33\n",
    "\n",
    "# calculates population of given district\n",
    "\n",
    "def district_pop(part, district_i):\n",
    "    pop = 0\n",
    "    for vtd in dict(part.parts)[district_i]:\n",
    "        pop += graph.nodes[vtd][\"TOT_POP\"]\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################3\n",
    "\n",
    "#calculates population of intersection of given district and county\n",
    "\n",
    "def intersection_pop(part, county_vtds, county_j, district_i):\n",
    "    intersection = [vtd for vtd in county_vtds[county_j] if vtd in dict(part.parts)[district_i]]\n",
    "    \n",
    "    pop = 0\n",
    "    for vtd in intersection:\n",
    "        pop += graph.nodes[vtd][\"TOT_POP\"]\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates power entropy\n",
    "\n",
    "def power_entropy(partition, rev, alpha):\n",
    "    entropy = 0\n",
    "    for county_j in counties:\n",
    "        inner_sum = 0\n",
    "        cpop = county_pop(rev,county_j)\n",
    "        q = cpop / totpop\n",
    "        for district_i in range(num_districts):\n",
    "            p = intersection_pop(partition,rev,county_j,district_i+1) / cpop\n",
    "            inner_sum += p ** (1 - alpha)\n",
    "        entropy += 1 / q * (inner_sum - 1)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################33\n",
    "\n",
    "# calculates Shannon entropy\n",
    "# rev is dictionary mapping county to list of VTDs in county\n",
    "\n",
    "def relative_entropy(partition, rev): \n",
    "    entropy = 0\n",
    "    for county_j in counties:\n",
    "        inner_sum = 0\n",
    "        cpop = county_pop(rev,county_j)\n",
    "        q = cpop / totpop\n",
    "        for district_i in range(num_districts):\n",
    "            p = intersection_pop(partition,rev,county_j,district_i+1) / cpop \n",
    "            if p != 0:\n",
    "                inner_sum += p * math.log(1/p,2)\n",
    "        entropy += q * inner_sum\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#county_vtds = county_splits_dict(starting_partition)\n",
    "#print(power_entropy(county_splits,vtds,total,0.5))\n",
    "rev = reverse_countydict() \n",
    "\n",
    "#print(Shannon_entropy(starting_partition,rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = county_splits_dict(starting_partition)\n",
    "sum( [ len([ dd for dd  in [dict(v) for v in d.values()] if k in dd.keys()]) > 1 for k in counties] )\n",
    "#print(our_split_score_1(starting_partition))\n",
    "#print(our_split_score_2(starting_partition))\n",
    "#print(too_many_pieces(starting_partition))\n",
    "#print(other_too_many_pieces(starting_partition))\n",
    "#print(district_splits_dict(county_splits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal = partial(\n",
    "        recom, pop_col=\"TOT_POP\", pop_target=totpop/num_districts, epsilon=0.02, node_repeats=1\n",
    "    )\n",
    "\n",
    "compactness_bound = constraints.UpperBound(\n",
    "        lambda p: len(p[\"cut_edges\"]), 2 * len(starting_partition[\"cut_edges\"])\n",
    "    )\n",
    "\n",
    "chain = MarkovChain(\n",
    "        proposal,\n",
    "        constraints=[\n",
    "            constraints.within_percent_of_ideal_population(starting_partition, 0.05),compactness_bound\n",
    "          #constraints.single_flip_contiguous#no_more_discontiguous\n",
    "        ],\n",
    "        accept=accept.always_accept,\n",
    "        initial_state=starting_partition,\n",
    "        total_steps=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = []\n",
    "\n",
    "\n",
    "t = 0\n",
    "for part in partitions:\n",
    "    entropy.append(relative_entropy(part,rev))\n",
    "        \n",
    "    \n",
    "    t += 1\n",
    "    if t % 100 == 0:\n",
    "        print(\"finished chain \" + str(t))\n",
    "            \n",
    "#np.savetxt(\"PA_cuts.txt\", cuts)\n",
    "#np.savetxt(\"PA_splittings.txt\", splittings)\n",
    "#np.savetxt(\"PA_power_entropy.txt\", power)\n",
    "#np.savetxt(\"PA_Shannon_entropy.txt\",Shannon)\n",
    "#np.savetxt(\"PA_Score1.txt\",score_1)\n",
    "#np.savetxt(\"PA_Score2.txt\",score_2)\n",
    "#np.savetxt(\"PA_moon.txt\",moon)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#colors = ['hotpink']\n",
    "#labels = ['VTD']\n",
    "#plt.figure()\n",
    "#for i in range(1):\n",
    "#    sns.distplot(score_1,kde=False, color=colors[i],label=labels[i])\n",
    "#plt.legend()\n",
    "#plt.xlabel(\"Score 1\")\n",
    "#plt.show()\n",
    "\n",
    "#plt.figure()\n",
    "#for i in range(1):\n",
    "#    sns.distplot(score_2,kde=False, color=colors[i],label=labels[i])\n",
    "#plt.legend()\n",
    "#plt.xlabel(\"Score 2\")\n",
    "#plt.show()\n",
    "\n",
    "#plt.figure()\n",
    "#for i in range(1):\n",
    "#    sns.distplot(pieces,kde=False, color=colors[i],label=labels[i])\n",
    "#plt.legend()\n",
    "#plt.xlabel(\"Too Many Splits\")\n",
    "#plt.show()\n",
    "\n",
    "#plt.figure()\n",
    "#for i in range(1):\n",
    "#    sns.distplot(power,kde=False, color=colors[i],label=labels[i])\n",
    "#plt.legend()\n",
    "#plt.xlabel(\"Power Entropy (alpha = 4/5)\")\n",
    "#plt.show()\n",
    "\n",
    "#plt.figure()\n",
    "#for i in range(1):\n",
    "#    sns.distplot(Shannon,kde=False, color=colors[i],label=labels[i])\n",
    "#plt.legend()\n",
    "#plt.xlabel(\"Shannon Entropy\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#CHANGE\n",
    "#plt.figure()\n",
    "#plt.hist(power)\n",
    "#plt.title(\"Histogram of Power Entropy (Alpha = 0.8)\")\n",
    "#plt.xlabel(\"Power Entropy\")\n",
    "#plt.savefig(\"PA_hist_power_entropy_5000.png\")\n",
    "#plt.show()\n",
    "\n",
    "#plt.figure()\n",
    "#plt.hist(Shannon)\n",
    "#plt.title(\"Histogram of Shannon Entropy\")\n",
    "#plt.xlabel(\"Shannon Entropy\")\n",
    "#plt.savefig(\"PA_hist_Shannon_entropy_5000.png\")\n",
    "#plt.show()\n",
    "\n",
    "#CHANGE\n",
    "#plt.figure()\n",
    "#plt.scatter(splittings, power)\n",
    "#plt.title(\"Power Entropy (Alpha = 0.8) vs. Number of Splits\")\n",
    "#plt.xlabel('Splits')\n",
    "#plt.ylabel('Power Entropy')\n",
    "#plt.xlim(min(splittings) - 5, max(splittings) + 5)\n",
    "#plt.savefig(\"PA_scatter_power_entropy_splits_5000.png\")\n",
    "#plt.show()\n",
    "\n",
    "#plt.figure()\n",
    "#plt.scatter(splittings, Shannon)\n",
    "#plt.title(\"Shannon Entropy vs. Number of Splits\")\n",
    "#plt.xlabel('Splits')\n",
    "#plt.ylabel('Shannon Entropy')\n",
    "#plt.xlim(min(splittings) - 5, max(splittings) + 5)\n",
    "#plt.savefig(\"PA_scatter_Shannon_entropy_splits_5000.png\")\n",
    "#plt.show()\n",
    "\n",
    "#CHANGE\n",
    "#plt.figure()\n",
    "#plt.scatter(cuts, power)\n",
    "#plt.title(\"Power Entropy (Alpha = 0.8) vs. Number of Cut Edges\")\n",
    "#plt.xlabel('Cut Edges')\n",
    "#plt.ylabel('Power Entropy')\n",
    "#plt.savefig(\"PA_scatter_power_entropy_cut_edges_5000.png\")\n",
    "#plt.show()\n",
    "\n",
    "#plt.figure()\n",
    "#plt.scatter(cuts, Shannon)\n",
    "#plt.title(\"Shannon Entropy vs. Number of Cut Edges\")\n",
    "#plt.xlabel('Cut Edges')\n",
    "#plt.ylabel('Shannon Entropy')\n",
    "#plt.savefig(\"PA_scatter_Shannon_entropy_cut_edges_5000.png\")\n",
    "#plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(moon, score_1)\n",
    "#plt.title(\"Internal Cut Edges vs Moon's Score\")\n",
    "plt.xlabel(\"Symmetric Entropy\")\n",
    "plt.ylabel('Internal Cut Edges')\n",
    "plt.savefig(\"PA_scatter_internal_cut_edges_moon_score_5000.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(moon, score_2)\n",
    "#plt.title(\"Coincident Boundaries vs Moon's Score\")\n",
    "plt.xlabel(\"Symmetric Entropy\")\n",
    "plt.ylabel('Coincident Boundaries')\n",
    "plt.savefig(\"PA_scatter_coincident_boundaries_moon_score_5000.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "from gerrychain import Graph, GeographicPartition, Partition, Election, accept\n",
    "from gerrychain.updaters import Tally, cut_edges\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from gerrychain.random import random\n",
    "import copy\n",
    "from gerrychain import MarkovChain\n",
    "from gerrychain.constraints import single_flip_contiguous\n",
    "from gerrychain.proposals import propose_random_flip, recom\n",
    "from gerrychain.accept import always_accept\n",
    "from gerrychain.metrics import polsby_popper\n",
    "from gerrychain import constraints\n",
    "from gerrychain.constraints import no_vanishing_districts\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations_with_replacement\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas\n",
    "import math\n",
    "#from IPython.display import clear_output\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# setup -- SLOW\n",
    "#shapefile = \"https://github.com/mggg-states/PA-shapefiles/PA/raw/master/PA_VTD.zip\"\n",
    "shapefile = \"https://github.com/mggg-states/PA-shapefiles/raw/master/PA/PA_VTD.zip\"\n",
    "print(\"loaded\")\n",
    "df = gpd.read_file(shapefile)\n",
    "print(\"saved\")\n",
    "county_col = \"COUNTYFP10\"\n",
    "pop_col = \"TOT_POP\"\n",
    "uid = \"GEOID10\"\n",
    "#county_col = \"County\"\n",
    "#uuid = \"VTD\"\n",
    "\n",
    "\n",
    "\n",
    "graph = Graph.from_geodataframe(df,ignore_errors=True)\n",
    "print(\"made graph\")\n",
    "graph.add_data(df,list(df))\n",
    "graph = nx.relabel_nodes(graph, df[uid])\n",
    "counties = (set(list(df[county_col])))\n",
    "countydict = dict(graph.nodes(data=county_col))\n",
    "elections = [\n",
    "    Election(\"PRES16\", {\"Democratic\": \"T16PRESD\", \"Republican\": \"T16PRESR\"}),\n",
    "]\n",
    "my_updaters = {\"population\": Tally(pop_col, alias=\"population\"), \"cut_edges\": cut_edges}\n",
    "election_updaters = {election.name: election for election in elections}\n",
    "my_updaters.update(election_updaters)\n",
    "starting_partition = GeographicPartition(\n",
    "    graph,\n",
    "    assignment=\"GOV\",\n",
    "    updaters=my_updaters\n",
    ")\n",
    "county_edge_count = {}\n",
    "for i in counties:\n",
    "    county_graph = graph.subgraph([n for n,v in graph.nodes(data = True) if v[county_col] == i])\n",
    "    total_edges = len(county_graph.edges())\n",
    "    county_edge_count[i] = total_edges\n",
    "def county_splits_dict(partition):\n",
    "    county_splits = {k:[] for k in counties}\n",
    "    county_splits = {  k:[countydict[v] for v in d] for k,d in partition.assignment.parts.items()   }\n",
    "    county_splits = {k: Counter(v) for k,v in county_splits.items()}\n",
    "    return county_splits\n",
    "countynodelist = {\n",
    "    county: frozenset(\n",
    "        [node for node in graph.nodes() if graph.nodes[node][county_col] == county]) for county in counties\n",
    "}\n",
    "county_subgraphs = {county: graph.subgraph([n for n in graph.nodes if graph.nodes[n][county_col] == county]) for county in counties}\n",
    "county_edges = {county: len(county_subgraphs[county].edges()) for county in counties}\n",
    "total_edges = sum(county_edges.values())\n",
    "def cut_edges_in_county(partition):\n",
    "   '''returns an integer score that is the sum over all the county scores. The scores are computed by taking\n",
    "      number of cut egdes and dividing by the number of total edges.\n",
    "   '''\n",
    "   county_cut_edge_dict = {}\n",
    "   cut_edge_set = partition[\"cut_edges\"]\n",
    "   for k in cut_edge_set:\n",
    "       vtd_1 = k[0]\n",
    "       vtd_2 = k[1]\n",
    "       county_1 = countydict.get(vtd_1)\n",
    "       county_2 = countydict.get(vtd_2)\n",
    "       if county_1 == county_2:\n",
    "           if county_1 in county_cut_edge_dict.keys():\n",
    "               county_cut_edge_dict[county_1] += 1\n",
    "           else:\n",
    "               county_cut_edge_dict[county_1] = 1\n",
    "   ratio_dict = {}\n",
    "   for i in county_cut_edge_dict.keys():\n",
    "       ratio = county_cut_edge_dict[i]/county_edge_count[i]\n",
    "       ratio_dict[i] = ratio\n",
    "   return sum(ratio_dict.values())\n",
    "\n",
    "def cut_edges_in_district(partition):\n",
    "    cut_edges_between = 0\n",
    "    cut_edge_set = partition[\"cut_edges\"]\n",
    "    for i in cut_edge_set:\n",
    "        vtd_1 = i[0]\n",
    "        vtd_2 = i[1]\n",
    "        county_1 = countydict.get(vtd_1)\n",
    "        county_2 = countydict.get(vtd_2)\n",
    "        if county_1 != county_2:\n",
    "            cut_edges_between += 1\n",
    "    num_cut_edges = len(cut_edge_set)\n",
    "    score = cut_edges_between/num_cut_edges\n",
    "    return score\n",
    "\n",
    "\n",
    "def num_of_splittings(partition):\n",
    "    dictionary = county_splits_dict(partition)\n",
    "    counter = 0\n",
    "    for district in dictionary.keys():\n",
    "        counter += len(dictionary[district])\n",
    "    return counter\n",
    "totpop = 0\n",
    "num_districts = 18\n",
    "for n in graph.nodes():\n",
    "    graph.node[n][pop_col] = int(graph.node[n][pop_col])\n",
    "    totpop += graph.node[n][pop_col]\n",
    "proposal = partial(\n",
    "        recom, pop_col=pop_col, pop_target=totpop/num_districts, epsilon=0.02, node_repeats=1\n",
    "    )\n",
    "compactness_bound = constraints.UpperBound(\n",
    "        lambda p: len(p[\"cut_edges\"]), 2 * len(starting_partition[\"cut_edges\"])\n",
    "    )\n",
    "chain = MarkovChain(\n",
    "        proposal,\n",
    "        constraints=[\n",
    "            constraints.within_percent_of_ideal_population(starting_partition, 0.05),compactness_bound\n",
    "          #constraints.single_flip_contiguous#no_more_discontiguous\n",
    "        ],\n",
    "        accept=accept.always_accept,\n",
    "        initial_state=starting_partition,\n",
    "        total_steps=2000\n",
    "    )\n",
    "#cuts = []\n",
    "#splittings = []\n",
    "#moon_metric_scores = [] #CHANGE\n",
    "##Shannon = []\n",
    "#EE = []\n",
    "our_metric1 = []\n",
    "our_metric2 = []\n",
    "seats_D = []\n",
    "t = 0\n",
    "i=1\n",
    "print(\"Starting MCMC\")\n",
    "for part in chain:\n",
    "    if i > 100:\n",
    "        #cuts.append(len(part[\"cut_edges\"]))\n",
    "        #splittings.append(num_of_splittings(part))\n",
    "        #moon_metric_scores.append(moon_score(part)) #CHANGE\n",
    "        #EE.append(edge_entropy(part))\n",
    "        #Shannon.append(Shannon_entropy(part,rev))\n",
    "        #our_metric1.append(cut_edges_in_county(part))\n",
    "        our_metric2.append(cut_edges_in_district(part))\n",
    "        seats_D.append(part[\"PRES16\"].seats(\"Democratic\"))\n",
    "        t += 1\n",
    "        if t % 100 == 0:\n",
    "            print(\"finished chain \" + str(t))\n",
    "    else:\n",
    "        i+=1\n",
    "        t+=1\n",
    "np.savetxt(\"PA_seats.txt\", seats_D)\n",
    "np.savetxt(\"PA_our_score.txt\", our_metric)\n",
    "plt.figure()\n",
    "plt.scatter(our_metric2, seats_D)\n",
    "plt.title(\"Coincident Boundaries vs Democratic seats\")\n",
    "plt.xlabel('Coincident Boundaries')\n",
    "plt.ylabel('Democratic seats')\n",
    "plt.savefig(\"PA_scatter_our_score2_seats_2000.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
